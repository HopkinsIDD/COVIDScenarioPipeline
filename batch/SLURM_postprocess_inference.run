#!/bin/bash
#SBATCH --nodes 1                      # Node PER JOB. Apparently this works on MARC
#SBATCH --ntasks-per-node 1            # MPI sense -> just 1.
#SBATCH --cpus-per-task 1              # No more than the number of CPU in a node. CPU <- coeur dans slurm
# #SBATCH --qos=week                     # Echo is authorized to launch week-long job
# #SBATCH --reservationname=COVID19

set -x

module purge
# on marcc this is anaconda3/2022.05 to circumvent anaconda python bug. Otherwise that is just anaconda 
module load anaconda
module load anaconda3/2022.05
conda activate covidSP
# in case conda not found
#source /home/jcblemai/.bashrc
#source ~/miniconda3/etc/profile.d/conda.sh # loading conda in case
#eval "$(conda shell.bash hook)"
which python
which Rscript

curl \
  -H "Title: $COVID_RUN_INDEX Done âœ…" \
  -H "Priority: urgent" \
  -H "Tags: warning,snail" \
  -d "TODO say how many failure and stuff" \
  ntfy.sh/flepimop_alerts

# get the slack credentials
source /data/struelo1/flepimop-code/slack_credentials.sh # populate $SLACK_TOKEN

python $COVID_PATH/scripts/postprocess_auto.py -c $COVID_CONFIG_PATH --run_id $COVID_RUN_INDEX --job-name $JOB_NAME --fs-results-path $FS_RESULTS_PATH --slack-token $SLACK_TOKEN

